model:
  api_type: "together"
  name: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
  max_tokens: 200
  temperature: 0.7
  top_k: 50
  top_p: 0.9
  repetition_penalty: 1.0
  stop: ["<|eot_id|>"]
  stream: true
experiment:
  experiment_series: "gerrig"
  output_dir: "./outputs/gerrig_experiment"
settings:
  use_alternative: false
  